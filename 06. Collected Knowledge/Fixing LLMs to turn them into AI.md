Image Classifiers are AI. They identify and classify objects.
However, LLMs are not.

LLMs play only with languages.
They do not deal with epistemology and connecting language to ideas.

So they can be used to convert written ideas to more easily digestible summaries.
However, they can't be used to infer new information.
# Support
While Stallman calls them "bullshit generator", and I think that's true, it's still good to find if you can get something useful out of pure bullshit.

> (I went in two division of thought from this; I really have to figure out how to properly represent writings in this thinking pattern XD. I'll organize them according to the **"broad divisions of thought"**, and **"the order in which I placed them"**, and according to **"the order in which I wrote the lines"**. I don't really remember the order in which I thought the lines XD; I'll also study this condition in [[Difficulties of Writing 1 - Representing the Diverse Flow of Thought]])
## Division 2 (Science isn't Always Developed Formally)
4] It's easier for people to say that science was built on proper methods in retrospect.
3] But in reality, many inventions were based on people simply messing around with things.

1] Poetry and beautiful works of Art have often been generated through accidents.
2] Meaning and Beauty don't always overlap.
## Division 1 (Example of Meaningfulness Coming From Bullshit)
5] For example, similar principles have been used to make AI that navigates obstacles or performs some other action, purely based on memory, without a direct knowledge of what that action implies.

6.1] There's also the question of how humans are able to infer knowledge

7] If I could take the standard atheist stance, (babies are taught, religion)

6.2] Also, human babies too are taught concepts by means of supervision. And only after learning association of words with languages can they ever form rational thoughts. Babies won't survive in the wild without proper supervision.

8] 

> I think by now, it's not necessary to mention the broad divisions, or even subdivisions, but only the **"line numbers"**
> 
> But I also realize that line numbers are only a specific form of discretization, and we often edit individual words, and more often than that, we edit letters within words, because of spelling mistakes. But meh, spelling mistakes may not be all that usual for a good typist.
> 
> I guess the only way to avoid this is to write with pen on paper. So I can't erase or add in new words. With the added rule of not striking lines
# Good Alternate Approaches
- Use them like Grammarly does (validate grammar)
- Use them to re-summarize information