- Is our thinking of "audio" in terms of frequencies correct?
- We do know sound is composed of vibrations, and hence sine waves.
- But audio is not sound, audio is the brain's response to a specific range of sound.
- Audio could be a macroscopic effect fundamentally, and a single frequency could simply be perceived as a combination of tones.
- For example, as ((tone a + tone b) - (tone c + tone d))
- The combination of the tones 'a' and 'b' could have a set of harmonics close to the combination of the tones 'c' and 'd'.
- That is to say, the brain could only understand tones, not individual frequencies.
- This is similar to how our eyes do not really understand specific frequencies of electromagnetic waves, but only the [[Spectral Responsivity|spectral response]] of the [[Tristimulus]] from the different types of photocells in our eyes.
- As for mathematical modelling, that would mean audio is not an effect formed directly sound, but is an effect formed from the perceived tones, which are directly formed from sound.

- In another way of thinking, is music composed of "beats"?